import findspark
findspark.init()
from pyspark.context import SparkContext
from pyspark.sql.session import SparkSession
from pyspark import SparkConf
from pyspark.sql import SQLContext
sc = SparkContext('local')
spark = SparkSession(sc)
sqlContext = SQLContext(sc)
df = spark.read.json('/Users/matthew/Desktop/finaldata.json').rdd
test = spark.createDataFrame(df)
test.show()
test.registerTempTable("raw")
data = sqlContext.sql("SELECT sentiment, state, team FROM raw")
data.show()
data.registerTempTable("data")
tabcnt = sqlContext.sql("SELECT COUNT(sentiment) AS cnt, state, team FROM data GROUP BY state, team")
tabcnt.show()
tabcnt.registerTempTable("tabcnt")
tabavg = sqlContext.sql("SELECT AVG(sentiment) AS avg, state, team FROM calsent GROUP BY state, team")
tabavg.show()
tabavg.registerTempTable("tabavg")
calsent = sqlContext.sql("SELECT sentiment, state, team FROM data WHERE sentiment != 0.0")
calsent.show()
calsent.registerTempTable("calsent")
calpd = calsent.toPandas()
temp2 = calpd.groupby(['team', 'state']).mean()
tmean = spark.createDataFrame(temp2)
tmean.registerTempTable("tmean")
tmean.show()
psent = sqlContext.sql("SELECT COUNT(sentiment) AS pos, state, team FROM calsent WHERE sentiment > 0.0 GROUP BY state, team")
psent.show()
psent.registerTempTable("psent")
nsent = sqlContext.sql("SELECT COUNT(sentiment) AS neg, state, team FROM calsent WHERE sentiment < 0.0 GROUP BY state, team")
nsent.show()
nsent.registerTempTable("nsent")
pnsent = sqlContext.sql("SELECT psent.pos/nsent.neg AS povern, psent.state, psent.team FROM psent,nsent WHERE psent.state = nsent.state AND psent.team = nsent.team")
pnsent.show()
pnsent.registerTempTable("pnsent")
final = sqlContext.sql("SELECT pnsent.state, pnsent.team, tabcnt.cnt AS cnt, tabavg.avg, pnsent.povern FROM tabcnt, tabavg, pnsent WHERE pnsent.state = tabcnt.state AND tabcnt.state = tabavg.state AND pnsent.team = tabcnt.team AND tabcnt.team = tabavg.team")
final.show()
final.registerTempTable("final")
final.toPandas().to_csv('/Users/matthew/Desktop/neo4jdata.csv')